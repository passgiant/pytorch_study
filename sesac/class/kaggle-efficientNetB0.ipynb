{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOq+MYH7Rii6jCFSuHZnQgF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## kaggle json 파일을 업로드"],"metadata":{"id":"Hi7iSbbxgd-n"}},{"cell_type":"code","source":["#!cat /root/.kaggle/kaggle.json"],"metadata":{"id":"2qO1wMpFlrIw","executionInfo":{"status":"ok","timestamp":1727660684249,"user_tz":-540,"elapsed":606,"user":{"displayName":"박희진","userId":"04727579243057026808"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Laq5ngJajJqD","executionInfo":{"status":"ok","timestamp":1727660652325,"user_tz":-540,"elapsed":1936,"user":{"displayName":"박희진","userId":"04727579243057026808"}}},"outputs":[],"source":["KAGGLE_UPLOAD = False\n","\n","if KAGGLE_UPLOAD:\n","    # /content/ 폴더에 kaggle.json을 업로드 (매번 colab노트북 생성시 반복)\n","    from google.colab import files\n","    files.upload()\n","else:\n","    kaggle_username = 'ventureparker'\n","    from google.colab import userdata\n","    kaggle_key = userdata.get(kaggle_username)"]},{"cell_type":"markdown","source":["### Kaggle.json파일 생성"],"metadata":{"id":"zZJe4BvUg7Nl"}},{"cell_type":"code","source":["import json\n","import os\n","\n","def create_kaggle_json(username, key, file_path):\n","    # 데이터 생성\n","    kaggle_data = {\n","        \"username\": username,\n","        \"key\": key\n","    }\n","\n","    # JSON 파일로 저장\n","    with open(file_path, 'w') as json_file:\n","        json.dump(kaggle_data, json_file)\n","\n","    print(f\"kaggle.json 파일이 '{os.path.abspath(file_path)}' 경로에 생성되었습니다.\")\n","\n","\n","\n","# kaggle.json 파일 생성 함수 호출\n","if KAGGLE_UPLOAD==False:\n","    # 사용자 정보 입력\n","    key = kaggle_key  # 여기에 key값을 입력하세요\n","    filename = 'kaggle.json'\n","    create_kaggle_json(kaggle_username, key, filename)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRMghKlDaFrM","executionInfo":{"status":"ok","timestamp":1727660690518,"user_tz":-540,"elapsed":576,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"d46df842-38e2-47e5-979d-20c9f5ab8bf0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle.json 파일이 '/content/kaggle.json' 경로에 생성되었습니다.\n"]}]},{"cell_type":"code","source":["!cat kaggle.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t4Pdp3FVbJz9","executionInfo":{"status":"ok","timestamp":1727660702244,"user_tz":-540,"elapsed":385,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"3077ee22-060f-4afc-f699-291bf5d8747d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["{\"username\": \"ventureparker\", \"key\": \"dd42a6316bbc050370e11511e7a91e9e\"}"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","os.makedirs('/root/.kaggle', exist_ok=True)\n","path = os.getcwd()\n","\n","# 파일을 복사하는데, 이미 복사된 경우 복사하지 않는다.\n","if not os.path.exists(os.path.join('/root/.kaggle','kaggle.json')):\n","    src = os.path.join(path,'kaggle.json')\n","    dst = os.path.join('/root/.kaggle', 'kaggle.json')\n","    shutil.copy(src,dst)\n","    print('파일 복사 완료')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBmlSVpHjWOq","executionInfo":{"status":"ok","timestamp":1727659402654,"user_tz":-540,"elapsed":521,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"91831272-6e0a-48ca-de56-b33f41277f2f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["파일 복사 완료\n"]}]},{"cell_type":"code","source":["!chmod 600 /root/.kaggle/kaggle.json\n","!kaggle competitions download -c dogs-vs-cats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMOfbdPjjOnG","executionInfo":{"status":"ok","timestamp":1727659429425,"user_tz":-540,"elapsed":23493,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"6d54b5bd-a4ee-4e46-b7f6-d71b9370b259"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading dogs-vs-cats.zip to /content\n"," 99% 808M/812M [00:21<00:00, 39.2MB/s]\n","100% 812M/812M [00:21<00:00, 39.2MB/s]\n"]}]},{"cell_type":"code","source":["# 압축파일 풀기 :하위 폴더 data에 풀기\n","!unzip -qq dogs-vs-cats.zip -d data"],"metadata":{"id":"XfTElP6ojgY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","\n","data = os.path.join(path,'data')\n","train_data = os.path.join(data,'train')\n","test_data = os.path.join(data,'test1')\n","\n","zip_file = zipfile.ZipFile(os.path.join(data,'train.zip'))\n","zip_file.extractall(path=data)\n","zip_file.close()\n","\n","zip_file = zipfile.ZipFile(os.path.join(data,'test1.zip'))\n","zip_file.extractall(path=data)\n","zip_file.close()"],"metadata":{"id":"3LvGEv2vjgb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터의 갯수\n","trainFiles = os.listdir(train_data)\n","testFiles = os.listdir(test_data)\n","# train : 12500개 cat, 12500개 dog\n","print(len(trainFiles))\n","# test : 레이블이 없는 이미지 12500개\n","print(len(testFiles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0Lwvs6ojgep","executionInfo":{"status":"ok","timestamp":1727502113864,"user_tz":-540,"elapsed":7,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"0a40f349-b161-45d2-f007-325cbdd5dca9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25000\n","12500\n"]}]},{"cell_type":"code","source":["!rm -rf sdata"],"metadata":{"id":"iTw698YrjpC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sdata = 'sdata'\n","tain_sdata = os.path.join(sdata,'train')\n","valid_sdata = os.path.join(sdata,'valid')\n","test_sdata = os.path.join(sdata,'test')\n","\n","os.makedirs(tain_sdata, exist_ok=True)\n","os.makedirs(valid_sdata, exist_ok=True)\n","os.makedirs(test_sdata, exist_ok=True)\n","\n","train_sdata_dog = os.path.join(tain_sdata,'dog')\n","train_sdata_cat = os.path.join(tain_sdata,'cat')\n","os.makedirs(train_sdata_dog, exist_ok=True)\n","os.makedirs(train_sdata_cat, exist_ok=True)\n","\n","valid_sdata_dog = os.path.join(valid_sdata,'dog')\n","valid_sdata_cat = os.path.join(valid_sdata,'cat')\n","os.makedirs(valid_sdata_dog, exist_ok=True)\n","os.makedirs(valid_sdata_cat, exist_ok=True)"],"metadata":{"id":"_IqexPfPjpFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 한 클래스의 이미지 갯수 * 2\n","train_num = 1000\n","valid_num = 500\n","test_num  = 1000\n","\n","train_range = [0, train_num-1]\n","valid_range = [train_num, train_num + valid_num -1]\n","test_range  = [train_num + valid_num, train_num + valid_num + test_num-1]\n","\n","print(train_range)\n","print(valid_range)\n","print(test_range)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X4R_0ZYtjpIA","executionInfo":{"status":"ok","timestamp":1727502113865,"user_tz":-540,"elapsed":6,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"02d3e84e-e6d2-4ba9-e901-5db97bac5a83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 999]\n","[1000, 1499]\n","[1500, 2499]\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# 데이터셋 디렉토리 경로 설정 (데이터셋이 저장된 경로로 수정하세요)\n","dataset_dir = 'data/train'\n","\n","# 새로운 train, valid, test 디렉토리 생성 경로\n","base_dir = 'sdata'\n","\n","# 클래스 목록\n","classes = ['dog', 'cat']\n","\n","# 폴더 경로 생성\n","train_dir = os.path.join(base_dir, 'train')\n","valid_dir = os.path.join(base_dir, 'valid')\n","test_dir = os.path.join(base_dir, 'test')\n","\n","# 폴더 생성 함수\n","def create_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","# train, valid, test 폴더 및 각각의 클래스 폴더 생성\n","for cls in classes:\n","    create_dir(os.path.join(train_dir, cls))\n","    create_dir(os.path.join(valid_dir, cls))\n","\n","# 이미지 복사 함수\n","def copy_images(start_idx, end_idx, src_dir, dst_dir, label):\n","    for i in range(start_idx, end_idx + 1):\n","        file_name = f'{label}.{i}.jpg'\n","        src_path = os.path.join(src_dir, file_name)\n","        dst_path = os.path.join(dst_dir, file_name)\n","        if os.path.exists(src_path):\n","            shutil.copy(src_path, dst_path)\n","\n","# 클래스별로 train, valid, test 데이터셋 구성\n","for cls in classes:\n","    # train dataset 구성 (0~999)\n","    copy_images(train_range[0], train_range[1], dataset_dir, os.path.join(train_dir, cls), cls)\n","\n","    # valid dataset 구성 (1000~1249)\n","    copy_images(valid_range[0], valid_range[1], dataset_dir, os.path.join(valid_dir, cls), cls)\n","\n","    # test dataset 구성 (1250~1499)\n","    copy_images(test_range[0], test_range[1], dataset_dir, os.path.join(test_dir), cls)\n","\n","print(\"데이터셋 분할 및 복사가 완료되었습니다.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6q3QJ6EcjOp1","executionInfo":{"status":"ok","timestamp":1727502114384,"user_tz":-540,"elapsed":523,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"708472ce-cc7d-4259-ac18-9508a3dc830f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["데이터셋 분할 및 복사가 완료되었습니다.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SD29pzOqj4MQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install timm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iyo5lSi2j4PV","executionInfo":{"status":"ok","timestamp":1727502126476,"user_tz":-540,"elapsed":4826,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"e9d288de-871f-45ad-90c8-56f9701c9487"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: timm\n","Successfully installed timm-1.0.9\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","import timm  # PyTorch Image Models (timm) 라이브러리\n","import os\n","from PIL import Image\n","from torch.utils.data import Dataset"],"metadata":{"id":"cYOkZJ9Qx6pA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch-ignite"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Z0KhLuH0M0Z","executionInfo":{"status":"ok","timestamp":1727502143469,"user_tz":-540,"elapsed":4539,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"687409aa-c418-4014-febe-71d90f8dda41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.5.1-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (2.4.1+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (24.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n","Downloading pytorch_ignite-0.5.1-py3-none-any.whl (312 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/312.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.5.1\n"]}]},{"cell_type":"code","source":["# Kaggle의 Dogs vs. Cats 데이터셋을 위한 CustomDataset 클래스 생성\n","class DogsVsCatsDataset(Dataset):\n","    def __init__(self, file_paths, labels, transform=None):\n","        self.file_paths = file_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.file_paths[idx]\n","        image = Image.open(img_path).convert(\"RGB\")\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label"],"metadata":{"id":"CAqPYnFHyGLn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 파일 경로와 레이블을 생성하는 함수\n","def get_file_paths_and_labels(dataset_dir):\n","    file_paths = []\n","    labels = []\n","\n","    for label, class_name in enumerate(['cat', 'dog']):\n","        class_dir = os.path.join(dataset_dir, class_name)\n","        for file_name in os.listdir(class_dir):\n","            file_paths.append(os.path.join(class_dir, file_name))\n","            labels.append(label)  # cat=0, dog=1\n","\n","    return file_paths, labels"],"metadata":{"id":"xFURQMzYyIo8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 디렉토리 경로 설정 (Kaggle 데이터셋 경로 설정)\n","train_dir = 'sdata/train'  # train 데이터셋 경로\n","valid_dir = 'sdata/valid'  # valid 데이터셋 경로\n","\n","# 학습 데이터셋 및 검증 데이터셋에 대한 파일 경로 및 레이블 생성\n","train_file_paths, train_labels = get_file_paths_and_labels(train_dir)\n","valid_file_paths, valid_labels = get_file_paths_and_labels(valid_dir)\n","\n","# 이미지 전처리 설정\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","valid_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# 데이터셋 준비\n","train_dataset = DogsVsCatsDataset(train_file_paths, train_labels, transform=train_transform)\n","valid_dataset = DogsVsCatsDataset(valid_file_paths, valid_labels, transform=valid_transform)\n","\n","# 데이터 로더 준비\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"snXvw3YHyBHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","# EfficientNetV2B0 모델 불러오기 (timm 라이브러리 사용)\n","model = timm.create_model('efficientnet_b0', pretrained=True)\n","\n","# 마지막 레이어의 입력 특징 수를 가져옵니다.\n","num_features = model.classifier.in_features\n","\n","# 이진 분류를 위한 새로운 분류기 추가 (마지막 레이어 수정)\n","model.classifier = nn.Sequential(\n","    nn.Linear(num_features, 1),  # 출력 노드를 1개로 설정 (이진 분류)\n","    nn.Sigmoid()  # Sigmoid 활성화 함수 추가\n",")\n","\n","# 모델을 GPU 또는 CPU에 할당\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","# 손실 함수와 최적화 알고리즘 설정\n","criterion = nn.BCELoss()  # 이진 크로스 엔트로피 손실 함수\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","# 학습율을 조정\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"],"metadata":{"id":"iAuQbFdzjOsW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# EarlyStopping 클래스\n","class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n","        \"\"\"\n","        Args:\n","            patience (int): 성능 개선이 없을 때 몇 번의 에포크까지 기다릴지.\n","            verbose (bool): True일 경우 개선될 때마다 메시지 출력.\n","            delta (float): 성능 개선으로 간주될 최소 변화량.\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = float('inf')\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","        score = -val_loss\n","        # 처음에 호출됐을때는 best_score가 None이라서 초기값을 설정\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        # 지금까지의 best_score와 현재 score를 비교\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            # patience값이 모두 충족했을때, 종료조건이 만족될때\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''검증 손실이 감소하면 모델을 저장합니다.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","            torch.save(model.state_dict(), self.path)  # 모델 상태 저장\n","        self.val_loss_min = val_loss\n","\n","# EarlyStopping 인스턴스 생성 (patience=10)\n","early_stopping = EarlyStopping(patience=10, verbose=True, path='efficientnet_b0_best.pth')"],"metadata":{"id":"XsVZ1oXNQHX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습 함수\n","def train_model(model, criterion, optimizer, train_loader, valid_loader, epochs):\n","    # 훈련 시작시 초기 lr을 로딩\n","    pre_lr = optimizer.param_groups[0]['lr']\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct = 0\n","\n","        # Training\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device).float()\n","\n","            # 모델 초기화\n","            optimizer.zero_grad()\n","\n","            # Forward propagation\n","            outputs = model(inputs).squeeze()  # (batch_size, 1) -> (batch_size,)\n","            loss = criterion(outputs, labels)\n","\n","            # Backward propagation\n","            loss.backward()\n","            optimizer.step()\n","\n","            # 손실과 정확도 계산\n","            running_loss += loss.item() * inputs.size(0)\n","            preds = (outputs >= 0.5).float()  # 0.5 이상은 1, 이하 0으로 이진화\n","            correct += torch.sum(preds == labels)\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        epoch_acc = correct.double() / len(train_loader.dataset)\n","\n","        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        val_correct = 0\n","        with torch.no_grad():\n","            for inputs, labels in valid_loader:\n","                inputs, labels = inputs.to(device), labels.to(device).float()\n","\n","                outputs = model(inputs).squeeze()\n","                loss = criterion(outputs, labels)\n","\n","                val_loss += loss.item() * inputs.size(0)\n","                preds = (outputs >= 0.5).float()\n","                val_correct += torch.sum(preds == labels)\n","\n","        val_epoch_loss = val_loss / len(valid_loader.dataset)\n","        val_epoch_acc = val_correct.double() / len(valid_loader.dataset)\n","\n","        print(f'valid_loss: {val_epoch_loss:.4f}, valid_acc: {val_epoch_acc:.4f}')\n","\n","        # ReduceLROnPlateau 스케줄러를 사용하여 검증 손실에 따라 학습률을 조정\n","        scheduler.step(val_epoch_loss)\n","\n","        # 현재 학습률 출력\n","        now_lr = optimizer.param_groups[0]['lr']\n","        if now_lr != pre_lr:\n","            pre_lr = now_lr\n","            lr_str = ', LR changed!!'\n","        else:\n","            lr_str = ''\n","\n","        print(f'learning_rate {epoch+1}: {now_lr:.8f}'+lr_str)\n","\n","        # EarlyStopping을 호출하여 학습 중단 여부 확인\n","        early_stopping(val_epoch_loss, model)\n","\n","        # 학습 중단 조건을 충족하면 break\n","        if early_stopping.early_stop:\n","            print(\"Early stopping triggered.\")\n","            break\n","        print('-' * 70)"],"metadata":{"id":"CK9IpXGwyX8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습\n","train_model(model, criterion, optimizer, train_loader, valid_loader, epochs=30)"],"metadata":{"id":"AEAwohcGyboA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727506820759,"user_tz":-540,"elapsed":311365,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"bf5fa37e-75e3-4ea3-f455-d11471c088ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30, Loss: 0.3135, Accuracy: 0.9110\n","valid_loss: 0.0714, valid_acc: 0.9780\n","learning_rate 1: 0.00010000\n","Validation loss decreased (inf --> 0.071388).  Saving model ...\n","----------------------------------------------------------------------\n","Epoch 2/30, Loss: 0.0519, Accuracy: 0.9890\n","valid_loss: 0.0510, valid_acc: 0.9810\n","learning_rate 2: 0.00010000\n","Validation loss decreased (0.071388 --> 0.050960).  Saving model ...\n","----------------------------------------------------------------------\n","Epoch 3/30, Loss: 0.0282, Accuracy: 0.9930\n","valid_loss: 0.0414, valid_acc: 0.9870\n","learning_rate 3: 0.00010000\n","Validation loss decreased (0.050960 --> 0.041408).  Saving model ...\n","----------------------------------------------------------------------\n","Epoch 4/30, Loss: 0.0097, Accuracy: 0.9990\n","valid_loss: 0.0399, valid_acc: 0.9870\n","learning_rate 4: 0.00010000\n","Validation loss decreased (0.041408 --> 0.039936).  Saving model ...\n","----------------------------------------------------------------------\n","Epoch 5/30, Loss: 0.0107, Accuracy: 0.9985\n","valid_loss: 0.0503, valid_acc: 0.9810\n","learning_rate 5: 0.00010000\n","EarlyStopping counter: 1 out of 10\n","----------------------------------------------------------------------\n","Epoch 6/30, Loss: 0.0056, Accuracy: 0.9995\n","valid_loss: 0.0440, valid_acc: 0.9840\n","learning_rate 6: 0.00010000\n","EarlyStopping counter: 2 out of 10\n","----------------------------------------------------------------------\n","Epoch 7/30, Loss: 0.0059, Accuracy: 0.9985\n","valid_loss: 0.0427, valid_acc: 0.9810\n","learning_rate 7: 0.00010000\n","EarlyStopping counter: 3 out of 10\n","----------------------------------------------------------------------\n","Epoch 8/30, Loss: 0.0034, Accuracy: 0.9995\n","valid_loss: 0.0430, valid_acc: 0.9810\n","learning_rate 8: 0.00005000, LR changed!!\n","EarlyStopping counter: 4 out of 10\n","----------------------------------------------------------------------\n","Epoch 9/30, Loss: 0.0017, Accuracy: 1.0000\n","valid_loss: 0.0433, valid_acc: 0.9820\n","learning_rate 9: 0.00005000\n","EarlyStopping counter: 5 out of 10\n","----------------------------------------------------------------------\n","Epoch 10/30, Loss: 0.0036, Accuracy: 0.9990\n","valid_loss: 0.0464, valid_acc: 0.9850\n","learning_rate 10: 0.00005000\n","EarlyStopping counter: 6 out of 10\n","----------------------------------------------------------------------\n","Epoch 11/30, Loss: 0.0017, Accuracy: 1.0000\n","valid_loss: 0.0413, valid_acc: 0.9840\n","learning_rate 11: 0.00005000\n","EarlyStopping counter: 7 out of 10\n","----------------------------------------------------------------------\n","Epoch 12/30, Loss: 0.0025, Accuracy: 0.9990\n","valid_loss: 0.0447, valid_acc: 0.9830\n","learning_rate 12: 0.00002500, LR changed!!\n","EarlyStopping counter: 8 out of 10\n","----------------------------------------------------------------------\n","Epoch 13/30, Loss: 0.0014, Accuracy: 1.0000\n","valid_loss: 0.0424, valid_acc: 0.9840\n","learning_rate 13: 0.00002500\n","EarlyStopping counter: 9 out of 10\n","----------------------------------------------------------------------\n","Epoch 14/30, Loss: 0.0009, Accuracy: 1.0000\n","valid_loss: 0.0415, valid_acc: 0.9840\n","learning_rate 14: 0.00002500\n","EarlyStopping counter: 10 out of 10\n","Early stopping triggered.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-PXMliv3h-ci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","modelPath = '/content/drive/MyDrive/model'\n","os.makedirs(modelPath, exist_ok=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3fqnXTIh_xh","executionInfo":{"status":"ok","timestamp":1727659619736,"user_tz":-540,"elapsed":20304,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"2825fc8d-e6a1-4485-d190-cd64e47e7626"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["modelPath = '/content/drive/MyDrive/model'\n","modelname = 'efficientnet_b0.pth'\n","\n","torch.save(model.state_dict(), os.path.join(modelPath, modelname))"],"metadata":{"id":"4u5GlYXhwNl8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델에 저장된 가중치 로드\n","model.load_state_dict(torch.load(os.path.join(modelPath, modelname)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvPa0NKnw46t","executionInfo":{"status":"ok","timestamp":1727462160376,"user_tz":-540,"elapsed":1024,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"3057b261-ecd5-4939-a16a-84c6d45215d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-18-32a5c037ceab>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(os.path.join(modelPath, modelname)))\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","# EfficientNetV2B0 모델 불러오기 (timm 라이브러리 사용)\n","model = timm.create_model('efficientnet_b0', pretrained=True)\n","\n","# EfficientNet-B0의 특징 추출기(frozen)를 고정시키기\n","for param in model.parameters():\n","    param.requires_grad = False  # 모든 파라미터 고정\n","\n","# 마지막 레이어의 입력 특징 수를 가져옵니다.\n","num_features = model.classifier.in_features\n","\n","# 이진 분류를 위한 새로운 분류기 추가 (마지막 레이어 수정)\n","model.classifier = nn.Sequential(\n","    torch.nn.Linear(num_features, 256),\n","    torch.nn.ReLU(),\n","    torch.nn.Dropout(0.5),\n","    torch.nn.Linear(256, 1),\n","    torch.nn.Sigmoid()\n",")\n","\n","# 분류기 부분만 학습되도록 파라미터 업데이트 설정\n","for param in model.classifier.parameters():\n","    param.requires_grad = True  # 분류기 부분만 학습 가능하게 설정\n","\n","# 모델을 GPU 또는 CPU에 할당\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","\n","# 손실 함수와 최적화 알고리즘 설정\n","criterion = nn.BCELoss()  # 이진 크로스 엔트로피 손실 함수\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n","early_stopping = EarlyStopping(patience=10, verbose=True, path='efficientnet_b0_best.pth')"],"metadata":{"id":"5XTT_RGjbCtt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model(model, criterion, optimizer, train_loader, valid_loader, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HM9skLcvcCsd","executionInfo":{"status":"ok","timestamp":1727507265061,"user_tz":-540,"elapsed":77819,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"d729fdd7-4725-46e2-c85f-528a914e30d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5, Loss: 0.5540, Accuracy: 0.8125\n","valid_loss: 0.3977, valid_acc: 0.9310\n","learning_rate 1: 0.00010000\n","Validation loss decreased (inf --> 0.397747).  Saving model ...\n","----------------------------------------------------------------------\n","Epoch 2/5, Loss: 0.3107, Accuracy: 0.9180\n","valid_loss: 0.2359, valid_acc: 0.9550\n","learning_rate 2: 0.00010000\n","Validation loss decreased (0.397747 --> 0.235873).  Saving model ...\n","----------------------------------------------------------------------\n","Epoch 3/5, Loss: 0.2179, Accuracy: 0.9425\n","valid_loss: 0.1829, valid_acc: 0.9630\n","learning_rate 3: 0.00010000\n","Validation loss decreased (0.235873 --> 0.182864).  Saving model ...\n","----------------------------------------------------------------------\n","Epoch 4/5, Loss: 0.1696, Accuracy: 0.9500\n","valid_loss: 0.1503, valid_acc: 0.9690\n","learning_rate 4: 0.00010000\n","Validation loss decreased (0.182864 --> 0.150334).  Saving model ...\n","----------------------------------------------------------------------\n","Epoch 5/5, Loss: 0.1503, Accuracy: 0.9535\n","valid_loss: 0.1360, valid_acc: 0.9660\n","learning_rate 5: 0.00010000\n","Validation loss decreased (0.150334 --> 0.136005).  Saving model ...\n","----------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I64u7Y33d4sn","executionInfo":{"status":"ok","timestamp":1727507441166,"user_tz":-540,"elapsed":5,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"9e793917-e295-4310-8fe6-940d5de23c59"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EfficientNet(\n","  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","  (bn1): BatchNormAct2d(\n","    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","    (drop): Identity()\n","    (act): SiLU(inplace=True)\n","  )\n","  (blocks): Sequential(\n","    (0): Sequential(\n","      (0): DepthwiseSeparableConv(\n","        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","        (bn1): BatchNormAct2d(\n","          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn2): BatchNormAct2d(\n","          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","    )\n","    (1): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","        (bn2): BatchNormAct2d(\n","          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","        (bn2): BatchNormAct2d(\n","          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","    )\n","    (2): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n","        (bn2): BatchNormAct2d(\n","          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n","        (bn2): BatchNormAct2d(\n","          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","    )\n","    (3): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","        (bn2): BatchNormAct2d(\n","          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","        (bn2): BatchNormAct2d(\n","          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","      (2): InvertedResidual(\n","        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","        (bn2): BatchNormAct2d(\n","          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","    )\n","    (4): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n","        (bn2): BatchNormAct2d(\n","          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","        (bn2): BatchNormAct2d(\n","          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","      (2): InvertedResidual(\n","        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n","        (bn2): BatchNormAct2d(\n","          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","    )\n","    (5): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n","        (bn2): BatchNormAct2d(\n","          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","      (1): InvertedResidual(\n","        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","        (bn2): BatchNormAct2d(\n","          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","      (2): InvertedResidual(\n","        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","        (bn2): BatchNormAct2d(\n","          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","      (3): InvertedResidual(\n","        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n","        (bn2): BatchNormAct2d(\n","          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","    )\n","    (6): Sequential(\n","      (0): InvertedResidual(\n","        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNormAct2d(\n","          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n","        (bn2): BatchNormAct2d(\n","          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): SiLU(inplace=True)\n","        )\n","        (aa): Identity()\n","        (se): SqueezeExcite(\n","          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n","          (act1): SiLU(inplace=True)\n","          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n","          (gate): Sigmoid()\n","        )\n","        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNormAct2d(\n","          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","          (drop): Identity()\n","          (act): Identity()\n","        )\n","        (drop_path): Identity()\n","      )\n","    )\n","  )\n","  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  (bn2): BatchNormAct2d(\n","    1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n","    (drop): Identity()\n","    (act): SiLU(inplace=True)\n","  )\n","  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=1280, out_features=256, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=256, out_features=1, bias=True)\n","    (4): Sigmoid()\n","  )\n",")"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["def display_parameters(model):\n","    # 학습 가능한 파라미터의 개수 출력\n","    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"Number of trainable parameters: {num_trainable_params}\")"],"metadata":{"id":"cnven_kYeWmh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for param in model.classifier.parameters():\n","    param.requires_grad = False  # 분류기 부분만 학습 가능하게 설정\n","\n","display_parameters(model)"],"metadata":{"id":"nAnzvYJCef5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 마지막 두 블록을 가져와서 requires_grad를 True로 설정\n","for param in model.blocks[-2:].parameters():\n","    param.requires_grad = True"],"metadata":{"id":"crgUkfp6coHg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 특정 레이어 이름을 기준으로 동결 해제\n","for name, param in model.named_parameters():\n","    if \"blocks.5\" in name or \"blocks.6\" in name:  # 예를 들어, 마지막 두 블록\n","        param.requires_grad = True\n","\n","display_parameters(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMVGhaMed0ud","executionInfo":{"status":"ok","timestamp":1727507812116,"user_tz":-540,"elapsed":515,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"4ee2e62f-7702-490c-d768-416e11b3a534"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of trainable parameters: 2743580\n"]}]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","    print(name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRu1HTL2e_pz","executionInfo":{"status":"ok","timestamp":1727507962197,"user_tz":-540,"elapsed":523,"user":{"displayName":"박희진","userId":"04727579243057026808"}},"outputId":"44eb3be3-dda4-4e2e-818d-4157a84805f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["conv_stem.weight\n","bn1.weight\n","bn1.bias\n","blocks.0.0.conv_dw.weight\n","blocks.0.0.bn1.weight\n","blocks.0.0.bn1.bias\n","blocks.0.0.se.conv_reduce.weight\n","blocks.0.0.se.conv_reduce.bias\n","blocks.0.0.se.conv_expand.weight\n","blocks.0.0.se.conv_expand.bias\n","blocks.0.0.conv_pw.weight\n","blocks.0.0.bn2.weight\n","blocks.0.0.bn2.bias\n","blocks.1.0.conv_pw.weight\n","blocks.1.0.bn1.weight\n","blocks.1.0.bn1.bias\n","blocks.1.0.conv_dw.weight\n","blocks.1.0.bn2.weight\n","blocks.1.0.bn2.bias\n","blocks.1.0.se.conv_reduce.weight\n","blocks.1.0.se.conv_reduce.bias\n","blocks.1.0.se.conv_expand.weight\n","blocks.1.0.se.conv_expand.bias\n","blocks.1.0.conv_pwl.weight\n","blocks.1.0.bn3.weight\n","blocks.1.0.bn3.bias\n","blocks.1.1.conv_pw.weight\n","blocks.1.1.bn1.weight\n","blocks.1.1.bn1.bias\n","blocks.1.1.conv_dw.weight\n","blocks.1.1.bn2.weight\n","blocks.1.1.bn2.bias\n","blocks.1.1.se.conv_reduce.weight\n","blocks.1.1.se.conv_reduce.bias\n","blocks.1.1.se.conv_expand.weight\n","blocks.1.1.se.conv_expand.bias\n","blocks.1.1.conv_pwl.weight\n","blocks.1.1.bn3.weight\n","blocks.1.1.bn3.bias\n","blocks.2.0.conv_pw.weight\n","blocks.2.0.bn1.weight\n","blocks.2.0.bn1.bias\n","blocks.2.0.conv_dw.weight\n","blocks.2.0.bn2.weight\n","blocks.2.0.bn2.bias\n","blocks.2.0.se.conv_reduce.weight\n","blocks.2.0.se.conv_reduce.bias\n","blocks.2.0.se.conv_expand.weight\n","blocks.2.0.se.conv_expand.bias\n","blocks.2.0.conv_pwl.weight\n","blocks.2.0.bn3.weight\n","blocks.2.0.bn3.bias\n","blocks.2.1.conv_pw.weight\n","blocks.2.1.bn1.weight\n","blocks.2.1.bn1.bias\n","blocks.2.1.conv_dw.weight\n","blocks.2.1.bn2.weight\n","blocks.2.1.bn2.bias\n","blocks.2.1.se.conv_reduce.weight\n","blocks.2.1.se.conv_reduce.bias\n","blocks.2.1.se.conv_expand.weight\n","blocks.2.1.se.conv_expand.bias\n","blocks.2.1.conv_pwl.weight\n","blocks.2.1.bn3.weight\n","blocks.2.1.bn3.bias\n","blocks.3.0.conv_pw.weight\n","blocks.3.0.bn1.weight\n","blocks.3.0.bn1.bias\n","blocks.3.0.conv_dw.weight\n","blocks.3.0.bn2.weight\n","blocks.3.0.bn2.bias\n","blocks.3.0.se.conv_reduce.weight\n","blocks.3.0.se.conv_reduce.bias\n","blocks.3.0.se.conv_expand.weight\n","blocks.3.0.se.conv_expand.bias\n","blocks.3.0.conv_pwl.weight\n","blocks.3.0.bn3.weight\n","blocks.3.0.bn3.bias\n","blocks.3.1.conv_pw.weight\n","blocks.3.1.bn1.weight\n","blocks.3.1.bn1.bias\n","blocks.3.1.conv_dw.weight\n","blocks.3.1.bn2.weight\n","blocks.3.1.bn2.bias\n","blocks.3.1.se.conv_reduce.weight\n","blocks.3.1.se.conv_reduce.bias\n","blocks.3.1.se.conv_expand.weight\n","blocks.3.1.se.conv_expand.bias\n","blocks.3.1.conv_pwl.weight\n","blocks.3.1.bn3.weight\n","blocks.3.1.bn3.bias\n","blocks.3.2.conv_pw.weight\n","blocks.3.2.bn1.weight\n","blocks.3.2.bn1.bias\n","blocks.3.2.conv_dw.weight\n","blocks.3.2.bn2.weight\n","blocks.3.2.bn2.bias\n","blocks.3.2.se.conv_reduce.weight\n","blocks.3.2.se.conv_reduce.bias\n","blocks.3.2.se.conv_expand.weight\n","blocks.3.2.se.conv_expand.bias\n","blocks.3.2.conv_pwl.weight\n","blocks.3.2.bn3.weight\n","blocks.3.2.bn3.bias\n","blocks.4.0.conv_pw.weight\n","blocks.4.0.bn1.weight\n","blocks.4.0.bn1.bias\n","blocks.4.0.conv_dw.weight\n","blocks.4.0.bn2.weight\n","blocks.4.0.bn2.bias\n","blocks.4.0.se.conv_reduce.weight\n","blocks.4.0.se.conv_reduce.bias\n","blocks.4.0.se.conv_expand.weight\n","blocks.4.0.se.conv_expand.bias\n","blocks.4.0.conv_pwl.weight\n","blocks.4.0.bn3.weight\n","blocks.4.0.bn3.bias\n","blocks.4.1.conv_pw.weight\n","blocks.4.1.bn1.weight\n","blocks.4.1.bn1.bias\n","blocks.4.1.conv_dw.weight\n","blocks.4.1.bn2.weight\n","blocks.4.1.bn2.bias\n","blocks.4.1.se.conv_reduce.weight\n","blocks.4.1.se.conv_reduce.bias\n","blocks.4.1.se.conv_expand.weight\n","blocks.4.1.se.conv_expand.bias\n","blocks.4.1.conv_pwl.weight\n","blocks.4.1.bn3.weight\n","blocks.4.1.bn3.bias\n","blocks.4.2.conv_pw.weight\n","blocks.4.2.bn1.weight\n","blocks.4.2.bn1.bias\n","blocks.4.2.conv_dw.weight\n","blocks.4.2.bn2.weight\n","blocks.4.2.bn2.bias\n","blocks.4.2.se.conv_reduce.weight\n","blocks.4.2.se.conv_reduce.bias\n","blocks.4.2.se.conv_expand.weight\n","blocks.4.2.se.conv_expand.bias\n","blocks.4.2.conv_pwl.weight\n","blocks.4.2.bn3.weight\n","blocks.4.2.bn3.bias\n","blocks.5.0.conv_pw.weight\n","blocks.5.0.bn1.weight\n","blocks.5.0.bn1.bias\n","blocks.5.0.conv_dw.weight\n","blocks.5.0.bn2.weight\n","blocks.5.0.bn2.bias\n","blocks.5.0.se.conv_reduce.weight\n","blocks.5.0.se.conv_reduce.bias\n","blocks.5.0.se.conv_expand.weight\n","blocks.5.0.se.conv_expand.bias\n","blocks.5.0.conv_pwl.weight\n","blocks.5.0.bn3.weight\n","blocks.5.0.bn3.bias\n","blocks.5.1.conv_pw.weight\n","blocks.5.1.bn1.weight\n","blocks.5.1.bn1.bias\n","blocks.5.1.conv_dw.weight\n","blocks.5.1.bn2.weight\n","blocks.5.1.bn2.bias\n","blocks.5.1.se.conv_reduce.weight\n","blocks.5.1.se.conv_reduce.bias\n","blocks.5.1.se.conv_expand.weight\n","blocks.5.1.se.conv_expand.bias\n","blocks.5.1.conv_pwl.weight\n","blocks.5.1.bn3.weight\n","blocks.5.1.bn3.bias\n","blocks.5.2.conv_pw.weight\n","blocks.5.2.bn1.weight\n","blocks.5.2.bn1.bias\n","blocks.5.2.conv_dw.weight\n","blocks.5.2.bn2.weight\n","blocks.5.2.bn2.bias\n","blocks.5.2.se.conv_reduce.weight\n","blocks.5.2.se.conv_reduce.bias\n","blocks.5.2.se.conv_expand.weight\n","blocks.5.2.se.conv_expand.bias\n","blocks.5.2.conv_pwl.weight\n","blocks.5.2.bn3.weight\n","blocks.5.2.bn3.bias\n","blocks.5.3.conv_pw.weight\n","blocks.5.3.bn1.weight\n","blocks.5.3.bn1.bias\n","blocks.5.3.conv_dw.weight\n","blocks.5.3.bn2.weight\n","blocks.5.3.bn2.bias\n","blocks.5.3.se.conv_reduce.weight\n","blocks.5.3.se.conv_reduce.bias\n","blocks.5.3.se.conv_expand.weight\n","blocks.5.3.se.conv_expand.bias\n","blocks.5.3.conv_pwl.weight\n","blocks.5.3.bn3.weight\n","blocks.5.3.bn3.bias\n","blocks.6.0.conv_pw.weight\n","blocks.6.0.bn1.weight\n","blocks.6.0.bn1.bias\n","blocks.6.0.conv_dw.weight\n","blocks.6.0.bn2.weight\n","blocks.6.0.bn2.bias\n","blocks.6.0.se.conv_reduce.weight\n","blocks.6.0.se.conv_reduce.bias\n","blocks.6.0.se.conv_expand.weight\n","blocks.6.0.se.conv_expand.bias\n","blocks.6.0.conv_pwl.weight\n","blocks.6.0.bn3.weight\n","blocks.6.0.bn3.bias\n","conv_head.weight\n","bn2.weight\n","bn2.bias\n","classifier.0.weight\n","classifier.0.bias\n","classifier.3.weight\n","classifier.3.bias\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lmGi_2qnfwqB"},"execution_count":null,"outputs":[]}]}