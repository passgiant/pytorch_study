{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.models as models\nfrom torchvision.models import ResNet50_Weights\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision.datasets import ImageFolder\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, f1_score\nimport numpy as np\nimport pandas as pd\n\n# Встановлення директорії даних\ndata_dir = '/kaggle/input/intel-image-classification'\n\n# Трансформації для тренувальних та тестових даних\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.RandomResizedCrop(150, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Завантаження даних\ntrain_data = ImageFolder(root=f\"{data_dir}/seg_train/seg_train\", transform=train_transform)\ntest_data = ImageFolder(root=f\"{data_dir}/seg_test/seg_test\", transform=test_transform)\n\ntrain_size = int(0.8 * len(train_data))\nval_size = len(train_data) - train_size\ntrain_dataset, val_dataset = random_split(train_data, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n\nclass ModifiedResNet50(nn.Module):\n    def __init__(self):\n        super(ModifiedResNet50, self).__init__()\n        self.base_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n        num_ftrs = self.base_model.fc.in_features\n        self.base_model.fc = nn.Linear(num_ftrs, 512)\n        self.dropout = nn.Dropout(0.5)\n        self.fc = nn.Linear(512, 6)\n\n    def forward(self, x):\n        x = self.base_model(x)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x\n\nmodel = ModifiedResNet50()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\nresults = []\n\ndef train_model(model, criterion, optimizer, num_epochs=10):\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        val_loss, val_acc, val_f1 = evaluate_model(model, val_loader)\n        results.append({\n            'epoch': epoch + 1,\n            'train_loss': running_loss / len(train_loader),\n            'val_loss': val_loss,\n            'val_accuracy': val_acc,\n            'val_f1_score': val_f1\n        })\n        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss}, Val Accuracy: {val_acc}%, Val F1-Score: {val_f1}\")\n\ndef evaluate_model(model, data_loader):\n    model.eval()\n    total = 0\n    correct = 0\n    loss_total = 0\n    all_targets = []\n    all_preds = []\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            loss_total += loss.item()\n            all_targets.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n    accuracy = 100 * correct / total\n    f1 = f1_score(all_targets, all_preds, average='macro')\n    return loss_total / len(data_loader), accuracy, f1\n\ntrain_model(model, criterion, optimizer, num_epochs=10)\nevaluate_model(model, test_loader)\n\n# Збереження результатів у CSV файл\ndf_results = pd.DataFrame(results)\ndf_results.to_csv('training_results.csv', index=False)\nprint(\"Results saved to 'training_results.csv'\")\n\n# Візуалізація матриці помилок\ndef plot_confusion_matrix(labels, predictions, class_names):\n    cm = confusion_matrix(labels, predictions)\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\n_, predictions, labels = evaluate_model(model, test_loader)\nplot_confusion_matrix(labels, predictions, train_data.classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T06:57:34.562154Z","iopub.execute_input":"2024-09-30T06:57:34.562552Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 168MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Завантаження результатів тренування з CSV\nresults_df = pd.read_csv('training_results.csv')\n\n# Відображення перших кількох рядків даних для перевірки\nprint(results_df.head())\n\n# Візуалізація динаміки зміни втрат і точності під час тренування\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(results_df['epoch'], results_df['train_loss'], label='Train Loss')\nplt.plot(results_df['epoch'], results_df['val_loss'], label='Validation Loss')\nplt.title('Loss over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(results_df['epoch'], results_df['val_accuracy'], label='Validation Accuracy', color='green')\nplt.title('Accuracy over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef evaluate_and_visualize(model, loader, dataset_type, results_df):\n    \"\"\" Оцінка моделі і візуалізація результатів для заданого набору даних. \"\"\"\n    model.eval()\n    all_labels = []\n    all_preds = []\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = 100 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_preds)\n    f1 = f1_score(all_labels, all_preds, average='macro')\n\n    # Зберігання результатів у DataFrame\n    new_row = pd.DataFrame({\n        'Dataset Type': [dataset_type],\n        'Accuracy': [accuracy],\n        'F1 Score': [f1]\n    })\n    results_df = pd.concat([results_df, new_row], ignore_index=True)\n\n    print(f\"{dataset_type} Accuracy: {accuracy:.2f}%\")\n    print(f\"{dataset_type} F1-Score: {f1:.4f}\")\n\n    # Візуалізація матриці помилок\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=train_data.classes, yticklabels=train_data.classes)\n    plt.title(f'Confusion Matrix for {dataset_type}')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\n    return results_df\n\n\n# Ініціалізація DataFrame для зберігання результатів\nresults_df = pd.DataFrame(columns=['Dataset Type', 'Accuracy', 'F1 Score'])\n\n# Візуалізація та збереження для тренувального, валідаційного та тестового наборів\nresults_df = evaluate_and_visualize(model, train_loader, 'Training', results_df)\nresults_df = evaluate_and_visualize(model, val_loader, 'Validation', results_df)\nresults_df = evaluate_and_visualize(model, test_loader, 'Testing', results_df)\n\n# Збереження результатів у CSV файл\nresults_df.to_csv('evaluation_results.csv', index=False)\nprint(\"Results saved to 'evaluation_results.csv'\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"На основі представлених результатів, модель показує високу продуктивність на тренувальному наборі даних з точністю 99.53% та F1-балом 0.9954. Це свідчить про те, що модель добре адаптувалась до навчальних даних, можливо, навіть занадто добре, що може вказувати на перенавчання. \n\nНа валідаційному наборі результати також досить високі з точністю 92.80% та F1-балом 0.9289. Це свідчить про те, що модель зберігає хорошу загальну продуктивність на даних, які вона раніше не бачила, але все ще є відмінність від тренувальних результатів.\n\nТестові результати є найкритичнішими Точність на тестовому наборі становить 93.83% із F1-балом 0.9396, що є відмінним показником і підтверджує, що модель ефективно узагальнює дані, які вона не бачила під час навчання.","metadata":{}},{"cell_type":"markdown","source":"Висновки:\nПеренавчання: Є незначна ознака перенавчання, оскільки результати на тренувальному наборі вищі за валідаційний та тестовий набори. Це може бути вирішено за допомогою технік регуляризації,  застосування більш агресивної аугментації даних.\n\nЗагальна продуктивність: Модель показує дуже хорошу продуктивність на валідаційному та тестовому наборах, що вказує на її ефективність і потенціал для застосування в реальних сценаріях.\n\nМожливості покращення: Для додаткового покращення моделі можна експериментувати з різними архітектурами, налаштуваннями гіперпараметрів або більш складними методами аугментації даних.\n\nПеревірка узагальнення: Висока точність та F1-бал на тестовому наборі підтверджують, що модель добре узагальнює інформацію, що є ключовим аспектом при розробці ефективних моделей глибокого навчання.","metadata":{}}]}